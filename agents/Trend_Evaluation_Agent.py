# bio_agent_code/agents/Trend_Evaluation_Agent.py
from __future__ import annotations
import os
import re
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from collections import Counter

from dotenv import load_dotenv
load_dotenv()

print("[INIT] Loading Trend Evaluation Agent...")



# ---------------------------------------------------------
# í”„ë¡œíŒŒì¼ë§ ì—°ê²° ìœ í‹¸ (ìƒˆë¡œ ì¶”ê°€)
# ---------------------------------------------------------
def ensure_profiling(state: PipelineState, profiling_runner=None) -> PipelineState:
    """
    Trend_Profiling_Agentê°€ ì•„ì§ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ìë™ìœ¼ë¡œ ì‹¤í–‰í•´
    state.academic_papersë¥¼ ì¤€ë¹„í•œë‹¤.
    - profiling_runner: callable(state) -> state í˜•íƒœë¥¼ ì¸ìë¡œ ë„˜ê¸°ë©´ ê·¸ê±¸ ì‚¬ìš©
    - ì—†ìœ¼ë©´ ì§€ì—° ì„í¬íŠ¸ë¡œ bio_agent_code.agents.Trend_Profiling_Agent.run ì‚¬ìš©
    """
    # ì´ë¯¸ ë…¼ë¬¸ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì§„í–‰
    if getattr(state, "academic_papers", None):
        state.log("[Evaluation] Profiling already present - skipping")
        return state

    # Discovery ê²°ê³¼ê°€ ì—†ìœ¼ë©´ í”„ë¡œíŒŒì¼ë§ì„ í•  ìˆ˜ ì—†ìŒ
    if not getattr(state, "discovered", None):
        state.log("[Evaluation] âœ— No discovered trends - cannot profile")
        return state

    state.log("[Evaluation] Academic papers missing - attempting to run Profiling Agent")

    # 1) í•¨ìˆ˜ê°€ ì¸ìë¡œ ë„˜ì–´ì˜¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if callable(profiling_runner):
        try:
            new_state = profiling_runner(state)
            state.log("[Evaluation] âœ“ Profiling runner completed")
            return new_state
        except Exception as e:
            state.log(f"[Evaluation] âœ— Profiling runner error: {e}")
            return state

    # 2) ì§€ì—° ì„í¬íŠ¸ë¡œ ë‚´ë¶€ ì—ì´ì „íŠ¸ ì‹¤í–‰ (ìˆœí™˜ì°¸ì¡° ë°©ì§€)
    try:
        from . import Trend_Profiling_Agent
        new_state = Trend_Profiling_Agent.run(state)
        state.log("[Evaluation] âœ“ Trend_Profiling_Agent.run executed (lazy import)")
        return new_state
    except Exception as e:
        state.log(f"[Evaluation] âœ— Could not import/run Trend_Profiling_Agent: {e}")
        return state


# ---------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ---------------------------------------------------------
def run(state: PipelineState, *, auto_profile: bool = True, profiling_runner=None) -> PipelineState:
    """
    Trend Evaluation Agent

    í”„ë¡œì„¸ìŠ¤:
    0. (ì˜µì…˜) Profiling ìë™ ì—°ê²°: state.academic_papersê°€ ì—†ìœ¼ë©´ Profiling ì‹¤í–‰
    1. state.academic_papersì—ì„œ íŠ¸ë Œë“œ ëª©ë¡ ì¶”ì¶œ
    2. ê° íŠ¸ë Œë“œì— ëŒ€í•´ ì„¸ ê°€ì§€ ì¶• ê³„ì‚°:
       - Current Presence (í˜„ì¬ ì¡´ì¬ê°)
       - Momentum (ì„±ì¥ ì†ë„)
       - Sustainability (ì§€ì† ê°€ëŠ¥ì„±)
    3. ë°œì „ ë°©í–¥ ë° ì‹œì¥ ì ìš© ê°€ëŠ¥ì„± ì˜ˆì¸¡
    4. state.evaluationsì— ê²°ê³¼ ì €ì¥

    íŒŒë¼ë¯¸í„°:
    - auto_profile: Trueì´ë©´ Profilingì´ ì•ˆ ë˜ì–´ ìˆì–´ë„ ìë™ ì‹¤í–‰
    - profiling_runner: ì™¸ë¶€ì—ì„œ ì „ë‹¬ ê°€ëŠ¥í•œ í•¨ìˆ˜ (í…ŒìŠ¤íŠ¸/ì£¼ì… ìš©ì´)
    """

    print("\n" + "="*80)
    print("ğŸ§­ TREND EVALUATION AGENT - START")
    print("="*80)

    state.log("[Evaluation] ========== START ==========")
    state.log(f"[Evaluation] Timestamp: {datetime.now().isoformat()}")

    # 0) í”„ë¡œíŒŒì¼ë§ ìë™ ì—°ê²°
    if auto_profile:
        before_cnt = len(getattr(state, "academic_papers", []) or [])
        state = ensure_profiling(state, profiling_runner=profiling_runner)
        after_cnt = len(getattr(state, "academic_papers", []) or [])
        state.log(f"[Evaluation] Profiling link: papers {before_cnt} -> {after_cnt}")

    if not getattr(state, "academic_papers", None):
        state.log("[Evaluation] âœ— ERROR: No academic papers to evaluate (profiling missing)")
        print("âš ï¸  No academic papers found - Skipping evaluation")
        return state




# --- ì™¸ë¶€ ì˜ì¡´ ---
try:
    from tavily import TavilyClient
    _HAS_TAVILY = True
    print("[INIT] âœ“ Tavily library imported")
except Exception as e:
    _HAS_TAVILY = False
    print(f"[INIT] âœ— Tavily import failed: {e}")

# --- ë‚´ë¶€ ì˜ì¡´ ---
from ..state import PipelineState, TrendItem, EvaluationMetrics

# ---------------------------------------------------------
# ì„¤ì •
# ---------------------------------------------------------
# ì‹œê°„ ë²”ìœ„
RECENT_12M = 365  # ìµœê·¼ 12ê°œì›”
PREVIOUS_12M = 730  # ì´ì „ 12ê°œì›” (12~24ê°œì›” ì „)

# ë°ì´í„° ì†ŒìŠ¤ ë„ë©”ì¸
FUNDING_DOMAINS = [
    "crunchbase.com",
    "pitchbook.com",
    "techcrunch.com"
]

POLICY_DOMAINS = [
    "who.int",
    "fda.gov",
    "oecd.org",
    "nih.gov"
]

NEWS_DOMAINS = [
    "labiotech.eu",
    "fiercebiotech.com",
    "nature.com",
    "science.org"
]

# ê°€ì¤‘ì¹˜
W_PAPER = 0.4
W_FUNDING = 0.3
W_NEWS = 0.3

W_PLAYER_DIVERSITY = 0.6
W_POLICY_STABILITY = 0.4

# ---------------------------------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ---------------------------------------------------------
def _norm(x: str) -> str:
    return (x or "").strip()

def _minmax_normalize(values: List[float]) -> List[float]:
    """Min-Max ì •ê·œí™” (0~1 ë²”ìœ„)"""
    if not values or len(values) == 0:
        return []
    
    min_val = min(values)
    max_val = max(values)
    
    if max_val == min_val:
        return [0.5 for _ in values]
    
    return [(v - min_val) / (max_val - min_val) for v in values]

def _z_normalize(values: List[float]) -> List[float]:
    """Z-score ì •ê·œí™”"""
    if not values or len(values) == 0:
        return []
    
    mean = sum(values) / len(values)
    variance = sum((x - mean) ** 2 for x in values) / len(values)
    std = variance ** 0.5
    
    if std == 0:
        return [0.0 for _ in values]
    
    return [(v - mean) / std for v in values]

def _classify_development_stage(presence: float, momentum: float, sustainability: float) -> str:
    """
    ì„¸ ì§€í‘œ ê¸°ë°˜ìœ¼ë¡œ ë°œì „ ë‹¨ê³„ ë¶„ë¥˜
    
    ë°˜í™˜ê°’:
    - "Emerging â†’ Growth" : ğŸš€ ê³ ì„±ì¥ + ì‹œì¥ ì§„ì…
    - "Mature" : ğŸ“ˆ ì•ˆì • ì„±ì¥
    - "Plateau" : âš ï¸ í¬í™”
    - "Seed Trend" : ğŸŒ± ì´ˆê¸° ì„±ì¥
    - "Hype" : ğŸ’¥ ë‹¨ê¸° ìœ í–‰
    - "Niche" : ğŸ§© ì ì¬ ì„±ì¥ ëŒ€ê¸°
    - "Decline" : ğŸª¦ ì‡ í‡´ ê¸°ìˆ 
    """
    # ì„ê³„ê°’ ì„¤ì • (ì •ê·œí™”ëœ ê°’ ê¸°ì¤€)
    HIGH_THRESHOLD = 0.6
    MID_THRESHOLD = 0.4
    LOW_THRESHOLD = 0.3
    
    # ë†’ìŒ/ë‚®ìŒ íŒë‹¨
    presence_high = presence >= HIGH_THRESHOLD
    presence_mid = MID_THRESHOLD <= presence < HIGH_THRESHOLD
    presence_low = presence < MID_THRESHOLD
    
    momentum_high = momentum >= HIGH_THRESHOLD
    momentum_low = momentum < LOW_THRESHOLD
    
    sustainability_high = sustainability >= HIGH_THRESHOLD
    sustainability_low = sustainability < LOW_THRESHOLD
    
    # ë¶„ë¥˜ ë¡œì§
    if presence_high and momentum_high and sustainability_high:
        return "ğŸš€ Emerging â†’ Growth"
    elif presence_high and not momentum_low and sustainability_high:
        return "ğŸ“ˆ Mature"
    elif presence_high and momentum_low and sustainability_low:
        return "âš ï¸ Plateau"
    elif presence_low and momentum_high and sustainability_high:
        return "ğŸŒ± Seed Trend"
    elif presence_low and momentum_high and sustainability_low:
        return "ğŸ’¥ Hype"
    elif presence_low and not momentum_low and sustainability_high:
        return "ğŸ§© Niche"
    else:
        return "ğŸª¦ Decline"

def _get_market_feasibility(stage: str) -> str:
    """ë°œì „ ë‹¨ê³„ë³„ ì‹œì¥ ì ìš© ê°€ëŠ¥ì„± íŒë‹¨"""
    feasibility_map = {
        "ğŸš€ Emerging â†’ Growth": "High - ë¹ ë¥¸ ì‹œì¥ í™•ì‚° ì˜ˆìƒ, ì¡°ê¸° íˆ¬ì ì ê¸°",
        "ğŸ“ˆ Mature": "High - ì•ˆì •ì  ì„±ì¥, ì¥ê¸° íˆ¬ì ì í•©",
        "âš ï¸ Plateau": "Medium - ì‹œì¥ í¬í™”, ì°¨ë³„í™” ì „ëµ í•„ìš”",
        "ğŸŒ± Seed Trend": "Medium-High - ì´ˆê¸° ë‹¨ê³„, ì„±ì¥ ì ì¬ë ¥ ë†’ìŒ",
        "ğŸ’¥ Hype": "Low-Medium - ë‹¨ê¸° ìœ í–‰ ê°€ëŠ¥ì„±, ì‹ ì¤‘í•œ ì ‘ê·¼ í•„ìš”",
        "ğŸ§© Niche": "Medium - íŠ¹ì • ë¶„ì•¼ ì„±ì¥ ê°€ëŠ¥ì„±, ì¥ê¸° ê´€ì°° í•„ìš”",
        "ğŸª¦ Decline": "Low - ê¸°ìˆ  ì‡ í‡´, íˆ¬ì ë¹„ê¶Œì¥"
    }
    return feasibility_map.get(stage, "Unknown")

# ---------------------------------------------------------
# 1ï¸âƒ£ Current Presence ê³„ì‚°
# ---------------------------------------------------------
def _calculate_current_presence(trend_title: str, state: PipelineState) -> Dict[str, float]:
    """
    í˜„ì¬ì˜ ì¡´ì¬ê° ê³„ì‚°
    
    ì§€í‘œ:
    - ë…¼ë¬¸ ìˆ˜ (ìµœê·¼ 12ê°œì›”)
    - íˆ¬ì ê±´ìˆ˜ (ìµœê·¼ 12ê°œì›”)
    - ë‰´ìŠ¤ ëŸ‰ (ìµœê·¼ 12ê°œì›”)
    
    ë°˜í™˜: {
        'paper_count_12m': int,
        'funding_count_12m': int,
        'news_count_12m': int,
        'presence_raw': float
    }
    """
    state.log(f"[Evaluation] Calculating Current Presence for: {trend_title}")
    
    # 1. ë…¼ë¬¸ ìˆ˜ (state.academic_papersì—ì„œ)
    paper_count = sum(1 for p in state.academic_papers if p.trend_title == trend_title)
    state.log(f"[Evaluation]   Paper count (12M): {paper_count}")
    
    # 2. íˆ¬ì ê±´ìˆ˜ (Crunchbase/TechCrunch ê²€ìƒ‰)
    funding_count = _search_funding_events(trend_title, days=RECENT_12M, state=state)
    state.log(f"[Evaluation]   Funding count (12M): {funding_count}")
    
    # 3. ë‰´ìŠ¤ ëŸ‰ (Labiotech/FierceBiotech ê²€ìƒ‰)
    news_count = _search_news_volume(trend_title, days=RECENT_12M, state=state)
    state.log(f"[Evaluation]   News count (12M): {news_count}")
    
    # ì›ì‹œ ì ìˆ˜ ê³„ì‚° (ì •ê·œí™” ì „)
    presence_raw = paper_count + funding_count + news_count
    
    return {
        'paper_count_12m': paper_count,
        'funding_count_12m': funding_count,
        'news_count_12m': news_count,
        'presence_raw': presence_raw
    }

def _search_funding_events(keyword: str, days: int, state: PipelineState) -> int:
    """íˆ¬ì ì´ë²¤íŠ¸ ê²€ìƒ‰ (Tavily ì‚¬ìš©)"""
    if not _HAS_TAVILY:
        state.log("[Evaluation] âš ï¸  Tavily not available for funding search")
        return 0
    
    api_key = os.getenv("TAVILY_API_KEY")
    if not api_key:
        state.log("[Evaluation] âš ï¸  TAVILY_API_KEY not found")
        return 0
    
    try:
        client = TavilyClient(api_key=api_key)
        query = f"{keyword} funding investment biotech"
        
        state.log(f"[Evaluation] Searching funding: '{query}' (last {days} days)")
        
        result = client.search(
            query=query,
            max_results=30,
            search_depth="basic",
            include_domains=FUNDING_DOMAINS,
            days=days
        )
        
        count = len(result.get("results", []))
        state.log(f"[Evaluation] âœ“ Found {count} funding-related articles")
        
        return count
        
    except Exception as e:
        state.log(f"[Evaluation] âœ— Funding search error: {str(e)}")
        return 0

def _search_news_volume(keyword: str, days: int, state: PipelineState) -> int:
    """ë‰´ìŠ¤ ê²€ìƒ‰ (Tavily ì‚¬ìš©)"""
    if not _HAS_TAVILY:
        state.log("[Evaluation] âš ï¸  Tavily not available for news search")
        return 0
    
    api_key = os.getenv("TAVILY_API_KEY")
    if not api_key:
        state.log("[Evaluation] âš ï¸  TAVILY_API_KEY not found")
        return 0
    
    try:
        client = TavilyClient(api_key=api_key)
        query = f"{keyword} biotech"
        
        state.log(f"[Evaluation] Searching news: '{query}' (last {days} days)")
        
        result = client.search(
            query=query,
            max_results=50,
            search_depth="basic",
            include_domains=NEWS_DOMAINS,
            days=days
        )
        
        count = len(result.get("results", []))
        state.log(f"[Evaluation] âœ“ Found {count} news articles")
        
        return count
        
    except Exception as e:
        state.log(f"[Evaluation] âœ— News search error: {str(e)}")
        return 0

# ---------------------------------------------------------
# 2ï¸âƒ£ Momentum ê³„ì‚°
# ---------------------------------------------------------
def _calculate_momentum(trend_title: str, current_presence: Dict, state: PipelineState) -> Dict[str, float]:
    """
    ì„±ì¥ ì†ë„ ê³„ì‚°
    
    ì§€í‘œ:
    - ë…¼ë¬¸ ì¦ê°€ìœ¨ (ìµœê·¼ 12M vs ì´ì „ 12M)
    - íˆ¬ì ì¦ê°€ìœ¨
    - ë‰´ìŠ¤ ì¦ê°€ìœ¨
    
    ë°˜í™˜: {
        'paper_growth': float,
        'funding_growth': float,
        'news_growth': float,
        'momentum_raw': float
    }
    """
    state.log(f"[Evaluation] Calculating Momentum for: {trend_title}")
    
    # ì´ì „ 12ê°œì›” ë°ì´í„° ìˆ˜ì§‘
    paper_count_prev = _count_papers_in_period(trend_title, days=PREVIOUS_12M, state=state)
    funding_count_prev = _search_funding_events(trend_title, days=PREVIOUS_12M, state=state)
    news_count_prev = _search_news_volume(trend_title, days=PREVIOUS_12M, state=state)
    
    state.log(f"[Evaluation]   Previous 12M: Papers={paper_count_prev}, Funding={funding_count_prev}, News={news_count_prev}")
    
    # ì¦ê°€ìœ¨ ê³„ì‚° (%)
    paper_growth = _calculate_growth_rate(
        current_presence['paper_count_12m'],
        paper_count_prev
    )
    
    funding_growth = _calculate_growth_rate(
        current_presence['funding_count_12m'],
        funding_count_prev
    )
    
    news_growth = _calculate_growth_rate(
        current_presence['news_count_12m'],
        news_count_prev
    )
    
    state.log(f"[Evaluation]   Growth rates: Paper={paper_growth:.1f}%, Funding={funding_growth:.1f}%, News={news_growth:.1f}%")
    
    # í‰ê·  ì¦ê°€ìœ¨
    momentum_raw = (paper_growth + funding_growth + news_growth) / 3
    
    return {
        'paper_growth': paper_growth,
        'funding_growth': funding_growth,
        'news_growth': news_growth,
        'momentum_raw': momentum_raw
    }

def _count_papers_in_period(trend_title: str, days: int, state: PipelineState) -> int:
    """íŠ¹ì • ê¸°ê°„ ë‚´ ë…¼ë¬¸ ìˆ˜ ì¹´ìš´íŠ¸ (ê°„ì ‘ ì¶”ì •)"""
    # ì‹¤ì œë¡œëŠ” state.academic_papersì˜ year ì •ë³´ë¥¼ í™œìš©í•´ì•¼ í•˜ì§€ë§Œ
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ í˜„ì¬ ë…¼ë¬¸ ìˆ˜ì˜ 60%ë¡œ ì¶”ì • (ì´ì „ ê¸°ê°„ì€ ë³´í†µ ë” ì ìŒ)
    current_count = sum(1 for p in state.academic_papers if p.trend_title == trend_title)
    return int(current_count * 0.6)

def _calculate_growth_rate(current: float, previous: float) -> float:
    """ì¦ê°€ìœ¨ ê³„ì‚° (%)"""
    if previous == 0:
        return 100.0 if current > 0 else 0.0
    
    return ((current - previous) / previous) * 100

# ---------------------------------------------------------
# 3ï¸âƒ£ Sustainability ê³„ì‚°
# ---------------------------------------------------------
def _calculate_sustainability(trend_title: str, state: PipelineState) -> Dict[str, float]:
    """
    ì§€ì† ê°€ëŠ¥ì„± ê³„ì‚°
    
    ì§€í‘œ:
    - í”Œë ˆì´ì–´ ë‹¤ì–‘ì„± (ê¸°ì—… ìœ í˜• ë‹¤ì–‘ë„)
    - ì •ì±… ì•ˆì •ì„± (ê¸ì •ì  ì •ì±… ë¬¸ì„œ ë¹„ìœ¨)
    
    ë°˜í™˜: {
        'player_diversity': float (0~1),
        'policy_stability': float (0~1),
        'sustainability_raw': float (0~1)
    }
    """
    state.log(f"[Evaluation] Calculating Sustainability for: {trend_title}")
    
    # 1. í”Œë ˆì´ì–´ ë‹¤ì–‘ì„±
    player_diversity = _assess_player_diversity(trend_title, state)
    state.log(f"[Evaluation]   Player diversity: {player_diversity:.3f}")
    
    # 2. ì •ì±… ì•ˆì •ì„±
    policy_stability = _assess_policy_stability(trend_title, state)
    state.log(f"[Evaluation]   Policy stability: {policy_stability:.3f}")
    
    # ê°€ì¤‘ í‰ê· 
    sustainability_raw = (
        W_PLAYER_DIVERSITY * player_diversity +
        W_POLICY_STABILITY * policy_stability
    )
    
    return {
        'player_diversity': player_diversity,
        'policy_stability': policy_stability,
        'sustainability_raw': sustainability_raw
    }

def _assess_player_diversity(trend_title: str, state: PipelineState) -> float:
    """
    í”Œë ˆì´ì–´ ë‹¤ì–‘ì„± í‰ê°€
    
    ë°©ë²•:
    1. Crunchbaseì—ì„œ ê´€ë ¨ ê¸°ì—… ê²€ìƒ‰
    2. ê¸°ì—… ìœ í˜• ë¶„ë¥˜ (Startup, Pharma, Research ë“±)
    3. ë‹¤ì–‘ì„± ì§€ìˆ˜ ê³„ì‚° (Shannon Entropy ë˜ëŠ” Simpson Index)
    """
    if not _HAS_TAVILY:
        return 0.5  # ê¸°ë³¸ê°’
    
    api_key = os.getenv("TAVILY_API_KEY")
    if not api_key:
        return 0.5
    
    try:
        client = TavilyClient(api_key=api_key)
        query = f"{trend_title} companies biotech pharmaceutical startup"
        
        state.log(f"[Evaluation] Searching companies: '{query}'")
        
        result = client.search(
            query=query,
            max_results=30,
            search_depth="basic",
            include_domains=FUNDING_DOMAINS
        )
        
        results = result.get("results", [])
        
        if not results:
            state.log("[Evaluation] âš ï¸  No company data found")
            return 0.3
        
        # ê¸°ì—… ìœ í˜• ë¶„ë¥˜ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
        type_counts = {
            'startup': 0,
            'pharma': 0,
            'research': 0,
            'tech': 0,
            'other': 0
        }
        
        for r in results:
            text = f"{r.get('title', '')} {r.get('content', '')}".lower()
            
            if any(kw in text for kw in ['startup', 'early-stage', 'seed']):
                type_counts['startup'] += 1
            elif any(kw in text for kw in ['pharmaceutical', 'pharma', 'drug', 'biopharma']):
                type_counts['pharma'] += 1
            elif any(kw in text for kw in ['research', 'university', 'institute', 'academic']):
                type_counts['research'] += 1
            elif any(kw in text for kw in ['tech', 'platform', 'ai', 'software']):
                type_counts['tech'] += 1
            else:
                type_counts['other'] += 1
        
        # Shannon Entropy ê³„ì‚° (ë‹¤ì–‘ì„± ì§€ìˆ˜)
        total = sum(type_counts.values())
        if total == 0:
            return 0.3
        
        entropy = 0.0
        for count in type_counts.values():
            if count > 0:
                p = count / total
                entropy -= p * (p ** 0.5)  # ê°„ë‹¨í•œ ë‹¤ì–‘ì„± ì§€ìˆ˜
        
        # ì •ê·œí™” (0~1)
        max_entropy = 2.0  # 5ê°œ ìœ í˜•ì´ ê· ë“±í•  ë•Œ ìµœëŒ€ê°’ ê·¼ì‚¬
        diversity_score = min(1.0, entropy / max_entropy)
        
        state.log(f"[Evaluation]   Company types: {type_counts}")
        state.log(f"[Evaluation]   Diversity score: {diversity_score:.3f}")
        
        return diversity_score
        
    except Exception as e:
        state.log(f"[Evaluation] âœ— Player diversity error: {str(e)}")
        return 0.5

def _assess_policy_stability(trend_title: str, state: PipelineState) -> float:
    """
    ì •ì±… ì•ˆì •ì„± í‰ê°€
    
    ë°©ë²•:
    1. WHO/FDA/OECD ë¬¸ì„œ ê²€ìƒ‰
    2. "AI biomedical" ê´€ë ¨ ë¬¸ì„œì—ì„œ ê¸ì •/ë¶€ì • ë¹„ìœ¨ ê³„ì‚°
    """
    if not _HAS_TAVILY:
        return 0.5  # ê¸°ë³¸ê°’
    
    api_key = os.getenv("TAVILY_API_KEY")
    if not api_key:
        return 0.5
    
    try:
        client = TavilyClient(api_key=api_key)
        query = f"{trend_title} AI biomedical regulation policy"
        
        state.log(f"[Evaluation] Searching policies: '{query}'")
        
        result = client.search(
            query=query,
            max_results=20,
            search_depth="basic",
            include_domains=POLICY_DOMAINS
        )
        
        results = result.get("results", [])
        
        if not results:
            state.log("[Evaluation] âš ï¸  No policy documents found")
            return 0.5
        
        # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ë¶„ì„
        positive_keywords = [
            'approve', 'support', 'encourage', 'advance', 'promote',
            'benefit', 'innovation', 'breakthrough', 'opportunity', 'potential'
        ]
        
        negative_keywords = [
            'risk', 'concern', 'caution', 'limitation', 'challenge',
            'restrict', 'prohibit', 'ban', 'danger', 'threat'
        ]
        
        positive_count = 0
        negative_count = 0
        
        for r in results:
            text = f"{r.get('title', '')} {r.get('content', '')}".lower()
            
            for kw in positive_keywords:
                if kw in text:
                    positive_count += 1
            
            for kw in negative_keywords:
                if kw in text:
                    negative_count += 1
        
        total = positive_count + negative_count
        if total == 0:
            return 0.5
        
        # ê¸ì • ë¹„ìœ¨
        positive_ratio = positive_count / total
        
        state.log(f"[Evaluation]   Policy sentiment: Positive={positive_count}, Negative={negative_count}")
        state.log(f"[Evaluation]   Positive ratio: {positive_ratio:.3f}")
        
        return positive_ratio
        
    except Exception as e:
        state.log(f"[Evaluation] âœ— Policy stability error: {str(e)}")
        return 0.5

# ---------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ---------------------------------------------------------
def run(state: PipelineState) -> PipelineState:
    """
    Trend Evaluation Agent
    
    í”„ë¡œì„¸ìŠ¤:
    1. state.academic_papersì—ì„œ íŠ¸ë Œë“œ ëª©ë¡ ì¶”ì¶œ
    2. ê° íŠ¸ë Œë“œì— ëŒ€í•´ ì„¸ ê°€ì§€ ì¶• ê³„ì‚°:
       - Current Presence (í˜„ì¬ ì¡´ì¬ê°)
       - Momentum (ì„±ì¥ ì†ë„)
       - Sustainability (ì§€ì† ê°€ëŠ¥ì„±)
    3. ë°œì „ ë°©í–¥ ë° ì‹œì¥ ì ìš© ê°€ëŠ¥ì„± ì˜ˆì¸¡
    4. state.evaluationsì— ê²°ê³¼ ì €ì¥
    """
    print("\n" + "="*80)
    print("ğŸ§­ TREND EVALUATION AGENT - START")
    print("="*80)
    
    state.log("[Evaluation] ========== START ==========")
    state.log(f"[Evaluation] Timestamp: {datetime.now().isoformat()}")
    
    if not state.academic_papers:
        state.log("[Evaluation] âœ— ERROR: No academic papers to evaluate")
        print("âš ï¸  No academic papers found - Skipping evaluation")
        return state
    
    # íŠ¸ë Œë“œ ëª©ë¡ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°)
    trend_titles = list(set(p.trend_title for p in state.academic_papers))
    state.log(f"[Evaluation] Found {len(trend_titles)} unique trends to evaluate")
    print(f"âœ“ Evaluating {len(trend_titles)} trends\n")
    
    # API í‚¤ ì²´í¬
    tavily_key = os.getenv("TAVILY_API_KEY")
    state.log(f"[Evaluation] TAVILY_API_KEY: {'âœ“ Found' if tavily_key else 'âœ— Missing'}")
    
    if not tavily_key:
        print("âš ï¸  WARNING: TAVILY_API_KEY not found - evaluation will use fallback values")
    
    all_evaluations = []
    
    # ì›ì‹œ ë°ì´í„° ìˆ˜ì§‘ (ì •ê·œí™” ì „)
    raw_data = []
    
    for trend_idx, trend_title in enumerate(trend_titles, 1):
        print(f"\n[{trend_idx}/{len(trend_titles)}] Evaluating: {trend_title}")
        state.log(f"[Evaluation] ========== TREND {trend_idx}/{len(trend_titles)}: {trend_title} ==========")
        
        try:
            # 1. Current Presence ê³„ì‚°
            state.log(f"[Evaluation] Step 1: Calculate Current Presence")
            presence_data = _calculate_current_presence(trend_title, state)
            
            # 2. Momentum ê³„ì‚°
            state.log(f"[Evaluation] Step 2: Calculate Momentum")
            momentum_data = _calculate_momentum(trend_title, presence_data, state)
            
            # 3. Sustainability ê³„ì‚°
            state.log(f"[Evaluation] Step 3: Calculate Sustainability")
            sustainability_data = _calculate_sustainability(trend_title, state)
            
            # ì›ì‹œ ë°ì´í„° ì €ì¥
            raw_data.append({
                'trend_title': trend_title,
                'presence_raw': presence_data['presence_raw'],
                'momentum_raw': momentum_data['momentum_raw'],
                'sustainability_raw': sustainability_data['sustainability_raw'],
                'presence_data': presence_data,
                'momentum_data': momentum_data,
                'sustainability_data': sustainability_data
            })
            
            print(f"  âœ“ Raw scores: Presence={presence_data['presence_raw']:.1f}, "
                  f"Momentum={momentum_data['momentum_raw']:.1f}%, "
                  f"Sustainability={sustainability_data['sustainability_raw']:.3f}")
            
        except Exception as e:
            state.log(f"[Evaluation] âœ— ERROR evaluating {trend_title}: {str(e)}")
            print(f"  âœ— ERROR: {str(e)}")
            import traceback
            state.log(f"[Evaluation] Stack trace:\n{traceback.format_exc()}")
            continue
    
    # ì •ê·œí™” (íŠ¸ë Œë“œ ê°„ ë¹„êµë¥¼ ìœ„í•´)
    if raw_data:
        state.log(f"[Evaluation] Step 4: Normalize scores across {len(raw_data)} trends")
        
        presence_raw_list = [d['presence_raw'] for d in raw_data]
        momentum_raw_list = [d['momentum_raw'] for d in raw_data]
        sustainability_raw_list = [d['sustainability_raw'] for d in raw_data]
        
        presence_normalized = _minmax_normalize(presence_raw_list)
        momentum_normalized = _minmax_normalize(momentum_raw_list)
        sustainability_normalized = _minmax_normalize(sustainability_raw_list)
        
        # EvaluationMetrics ìƒì„±
        for idx, raw in enumerate(raw_data):
            presence_norm = presence_normalized[idx]
            momentum_norm = momentum_normalized[idx]
            sustainability_norm = sustainability_normalized[idx]
            
            # ë°œì „ ë‹¨ê³„ ë¶„ë¥˜
            stage = _classify_development_stage(
                presence_norm,
                momentum_norm,
                sustainability_norm
            )
            
            # ì‹œì¥ ì ìš© ê°€ëŠ¥ì„±
            feasibility = _get_market_feasibility(stage)
            
            # EvaluationMetrics ê°ì²´ ìƒì„±
            eval_metrics = EvaluationMetrics(
                trend_title=raw['trend_title'],
                current_presence=presence_norm,
                momentum=momentum_norm,
                sustainability=sustainability_norm,
                development_stage=stage,
                market_feasibility=feasibility,
                presence_details=raw['presence_data'],
                momentum_details=raw['momentum_data'],
                sustainability_details=raw['sustainability_data']
            )
            
            all_evaluations.append(eval_metrics)
            state.log(f"[Evaluation] âœ“ {raw['trend_title']}: Stage={stage}, Feasibility={feasibility[:30]}...")
    
    # stateì— ì €ì¥
    state.evaluations = all_evaluations
    state.log(f"[Evaluation] ========== COMPLETE ==========")
    state.log(f"[Evaluation] Total evaluations: {len(all_evaluations)}")
    
    # í„°ë¯¸ë„ì— ê²°ê³¼ ì¶œë ¥
    _print_evaluation_summary(state)
    
    return state

def _print_evaluation_summary(state: PipelineState) -> None:
    """
    í„°ë¯¸ë„ì— ìµœì¢… í‰ê°€ ê²°ê³¼ ì¶œë ¥
    """
    print("\n" + "="*80)
    print("ğŸ“Š TREND EVALUATION AGENT - RESULTS SUMMARY")
    print("="*80)
    
    if not state.evaluations:
        print("âš ï¸  No evaluations generated")
        return
    
    print(f"\nâœ“ Total Trends Evaluated: {len(state.evaluations)}")
    print("\n" + "-"*80)
    
    # ë°œì „ ë‹¨ê³„ë³„ë¡œ ì •ë ¬
    evaluations_sorted = sorted(
        state.evaluations,
        key=lambda e: (e.current_presence + e.momentum + e.sustainability) / 3,
        reverse=True
    )
    
    for idx, eval_m in enumerate(evaluations_sorted, 1):
        print(f"\n[{idx}] {eval_m.trend_title}")
        print(f"    Development Stage: {eval_m.development_stage}")
        print(f"    Market Feasibility: {eval_m.market_feasibility}")
        print(f"    Scores (normalized 0~1):")
        print(f"      - Current Presence: {eval_m.current_presence:.3f}")
        print(f"      - Momentum: {eval_m.momentum:.3f}")
        print(f"      - Sustainability: {eval_m.sustainability:.3f}")
        print(f"    Details:")
        print(f"      - Papers(12M): {eval_m.presence_details['paper_count_12m']}")
        print(f"      - Funding(12M): {eval_m.presence_details['funding_count_12m']}")
        print(f"      - News(12M): {eval_m.presence_details['news_count_12m']}")
        print(f"      - Growth Rate: {eval_m.momentum_details['momentum_raw']:.1f}%")
    
    print("\n" + "="*80)
    print("âœ“ Evaluation Complete - Data saved to state.evaluations")
    print("="*80 + "\n")


# ---------------------------------------------------------
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì½”ë“œ
# ---------------------------------------------------------
if __name__ == "__main__":
    print("=" * 80)
    print("Trend Evaluation Agent í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    print("=" * 80)
    
    # í•„ìš”í•œ API í‚¤ í™•ì¸
    tavily_key = os.getenv("TAVILY_API_KEY")
    anthropic_key = os.getenv("ANTHROPIC_API_KEY")
    
    if not tavily_key:
        print("\n[ERROR] TAVILY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ .env íŒŒì¼ì— API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”:")
        print("echo 'TAVILY_API_KEY=your_api_key_here' >> .env")
        exit(1)
    
    print(f"\nâœ“ TAVILY_API_KEY í™•ì¸ë¨: {tavily_key[:10]}...")
    
    if anthropic_key:
        print(f"âœ“ ANTHROPIC_API_KEY í™•ì¸ë¨: {anthropic_key[:10]}...")
    else:
        print("âš ï¸  ANTHROPIC_API_KEY ì—†ìŒ (Profiling Agentì—ì„œ fallback ì‚¬ìš©)")
    
    # Tavily ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
    if not _HAS_TAVILY:
        print("\n[ERROR] Tavily ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("pip install tavily-python")
        exit(1)
    
    print("\n" + "="*80)
    print("ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Discovery â†’ Profiling â†’ Evaluation)")
    print("="*80)
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    try:
        # ëª¨ë“ˆ ì„í¬íŠ¸
        print("\n[1/4] ëª¨ë“ˆ ì„í¬íŠ¸ ì¤‘...")
        from . import Trend_Discovery_Agent, Trend_Profiling_Agent
        
        print("âœ“ ëª¨ë“ˆ ì„í¬íŠ¸ ì™„ë£Œ")
        
        # State ì´ˆê¸°í™” (ìƒìœ„ 3ê°œ íŠ¸ë Œë“œë§Œ í…ŒìŠ¤íŠ¸)
        print("\n[2/4] State ì´ˆê¸°í™” (target_count=3)...")
        test_state = PipelineState(target_count=3)
        print("âœ“ State ì´ˆê¸°í™” ì™„ë£Œ")
        
        # Discovery Agent ì‹¤í–‰
        print("\n[3/4] Trend Discovery Agent ì‹¤í–‰ ì¤‘...")
        print("-" * 80)
        test_state = Trend_Discovery_Agent.run(test_state)
        
        if not test_state.discovered:
            print("\n[ERROR] Discovery Agentì—ì„œ íŠ¸ë Œë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
            print("TAVILY_API_KEYë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
            exit(1)
        
        print(f"\nâœ“ Discovery ì™„ë£Œ: {len(test_state.discovered)}ê°œ íŠ¸ë Œë“œ ë°œê²¬")
        
        # Profiling Agent ì‹¤í–‰
        print("\n[4/4] Trend Profiling Agent ì‹¤í–‰ ì¤‘...")
        print("-" * 80)
        test_state = Trend_Profiling_Agent.run(test_state)
        
        if not test_state.academic_papers:
            print("\n[ERROR] Profiling Agentì—ì„œ ë…¼ë¬¸ì„ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!")
            exit(1)
        
        print(f"\nâœ“ Profiling ì™„ë£Œ: {len(test_state.academic_papers)}ê°œ ë…¼ë¬¸ ìˆ˜ì§‘")
        
        # Evaluation Agent ì‹¤í–‰ (í˜„ì¬ ì—ì´ì „íŠ¸)
        print("\n[5/5] Trend Evaluation Agent ì‹¤í–‰ ì¤‘...")
        print("=" * 80)
        test_state = run(test_state)
        
        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
        print("="*80)
        
        if test_state.evaluations:
            print(f"\nâœ“ ì´ {len(test_state.evaluations)}ê°œ íŠ¸ë Œë“œ í‰ê°€ ì™„ë£Œ\n")
            
            # ê° íŠ¸ë Œë“œë³„ ìš”ì•½
            for idx, eval_m in enumerate(test_state.evaluations, 1):
                print(f"\n[{idx}] {eval_m.trend_title}")
                print(f"    ğŸ¯ ë°œì „ ë‹¨ê³„: {eval_m.development_stage}")
                print(f"    ğŸ“Š ì‹œì¥ ì ìš© ê°€ëŠ¥ì„±: {eval_m.market_feasibility[:50]}...")
                print(f"    ğŸ“ˆ ì ìˆ˜:")
                print(f"       - Current Presence: {eval_m.current_presence:.3f}")
                print(f"       - Momentum: {eval_m.momentum:.3f}")
                print(f"       - Sustainability: {eval_m.sustainability:.3f}")
                print(f"    ğŸ“„ ë°ì´í„°:")
                print(f"       - ë…¼ë¬¸: {eval_m.presence_details.get('paper_count_12m', 0)}ê°œ")
                print(f"       - íˆ¬ì: {eval_m.presence_details.get('funding_count_12m', 0)}ê±´")
                print(f"       - ë‰´ìŠ¤: {eval_m.presence_details.get('news_count_12m', 0)}ê°œ")
                print(f"       - ì„±ì¥ë¥ : {eval_m.momentum_details.get('momentum_raw', 0):.1f}%")
            
            print("\n" + "="*80)
            print("ë‹¤ìŒ ë‹¨ê³„: Risk & Opportunity Agentì— state.evaluations ì „ë‹¬")
            print("="*80)
        else:
            print("\nâš ï¸  í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
    except ImportError as e:
        print(f"\n[ERROR] ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        print("\nì´ ì—ì´ì „íŠ¸ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì˜ ì¼ë¶€ì…ë‹ˆë‹¤.")
        print("ê°œë³„ ì‹¤í–‰ì´ ì•„ë‹Œ ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•˜ì„¸ìš”:\n")
        print("```python")
        print("from bio_agent_code.agents import (")
        print("    Trend_Discovery_Agent,")
        print("    Trend_Profiling_Agent,")
        print("    Trend_Evaluation_Agent")
        print(")")
        print("from bio_agent_code.state import PipelineState")
        print("")
        print("state = PipelineState(target_count=5)")
        print("state = Trend_Discovery_Agent.run(state)")
        print("state = Trend_Profiling_Agent.run(state)")
        print("state = Trend_Evaluation_Agent.run(state)")
        print("")
        print("# ê²°ê³¼ í™•ì¸")
        print("for eval in state.evaluations:")
        print("    print(f'{eval.trend_title}: {eval.development_stage}')")
        print("```")
        print("\n" + "="*80)
    
    except Exception as e:
        print(f"\n[ERROR] ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        print("\n" + "="*80)